"""
ComfyUIè§†é¢‘å­—å¹•ç”ŸæˆèŠ‚ç‚¹ï¼ˆä½¿ç”¨é¢„åŠ è½½æ¨¡å‹ç‰ˆæœ¬ï¼‰
æ”¯æŒæ¥æ”¶é¢„åŠ è½½çš„Whisperæ¨¡å‹ï¼Œé¿å…é‡å¤åŠ è½½
"""

import os
import sys
import tempfile
import logging
import time
from typing import Dict, Any, Tuple
import folder_paths
# æ·»åŠ çˆ¶ç›®å½•åˆ°Pythonè·¯å¾„ä»¥æ”¯æŒå¯¼å…¥
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

# å¯¼å…¥æœåŠ¡å’Œæ ¸å¿ƒæ¨¡å—
try:
    from ..services.audio_service import AudioService
    from ..services.subtitle_service import SubtitleService
    from ..services.video_service import VideoService
    from ..services.whisper_service import WhisperService
    from ..core.subtitle_style import SubtitlePosition, PresetStyles
except ImportError:
    try:
        from services.audio_service import AudioService
        from services.subtitle_service import SubtitleService
        from services.video_service import VideoService
        from services.whisper_service import WhisperService
        from core.subtitle_style import SubtitlePosition, PresetStyles
    except ImportError:
        from audio_service import AudioService
        from subtitle_service import SubtitleService
        from video_service import VideoService
        from whisper_service import WhisperService


def flush_line(line_text, line_start, end_time, transcript_lines):
    """å°†å½“å‰ç´¯è®¡çš„è¡Œå†™å…¥ transcript_linesï¼Œå¹¶é‡ç½®è¡ŒçŠ¶æ€ã€‚

    è¿”å›é‡ç½®åçš„ (line_text, line_start)ã€‚
    """
    text_out = (line_text or "").strip()
    if text_out and line_start is not None:
        transcript_lines.append(
            f"[{line_start:.2f}s -> {end_time:.2f}s] {text_out}"
        )
    return "", None


class VideoSubtitleWithModelNode:
    """ComfyUIè§†é¢‘å­—å¹•æ·»åŠ èŠ‚ç‚¹ï¼ˆä½¿ç”¨é¢„åŠ è½½æ¨¡å‹ï¼‰"""
    
    def __init__(self):
        self.audio_service = AudioService()
        self.subtitle_service = SubtitleService()
        self.video_service = VideoService()
        
    @classmethod
    def INPUT_TYPES(cls):
        """å®šä¹‰èŠ‚ç‚¹è¾“å…¥ç±»å‹"""
        return {
            "required": {
                "whisper_model": ("WHISPER_MODEL", {
                    "tooltip": "ä»Whisperæ¨¡å‹åŠ è½½èŠ‚ç‚¹è·å–çš„é¢„åŠ è½½æ¨¡å‹"
                }),
                "video_path": ("STRING", {
                    "default": "",
                    "multiline": False,
                    "placeholder": "è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„"
                }),
                "output_prefix": ("STRING", {
                    "default": "subtitle_output",
                    "multiline": False,
                    "placeholder": "è¾“å‡ºç›®å½•å‰ç¼€ï¼ˆå°†æ‹¼æ¥åˆ°ComfyUIè¾“å‡ºç›®å½•åï¼‰"
                }),
                "output_mode": ([
                    "line",
                    "word",
                ], {
                    "default": "line",
                    "tooltip": "å­—å¹•è¾“å‡ºç²’åº¦ï¼šline=æŒ‰æ ‡ç‚¹æ¢è¡Œçš„å¥å­ï¼›word=æŒ‰è¯"
                }),
                "subtitle_style": ([
                    "default", "cinema", "youtube", "minimal", 
                    "top_news", "strong_shadow", "dramatic_shadow"
                ], {
                    "default": "strong_shadow",
                    "tooltip": "é¢„è®¾å­—å¹•æ ·å¼"
                })
            },
            "optional": {
                "custom_font_size": ("INT", {
                    "default": 24,
                    "min": 12,
                    "max": 72,
                    "step": 1,
                    "tooltip": "è‡ªå®šä¹‰å­—ä½“å¤§å°"
                }),
                "max_chars_per_line": ("INT", {
                    "default": 30,
                    "min": 10,
                    "max": 120,
                    "step": 1,
                    "tooltip": "è¡Œæ¨¡å¼ï¼šå•æ¡å­—å¹•æœ€å¤§å­—ç¬¦æ•°ï¼Œè¾¾åˆ°åæå‰æ¢è¡Œ"
                }),
                "custom_position": ([
                    "none", "bottom_center", "bottom_left", "bottom_right",
                    "top_center", "top_left", "top_right", "center"
                ], {
                    "default": "none",
                    "tooltip": "è‡ªå®šä¹‰å­—å¹•ä½ç½®"
                }),
                "font_color_r": ("INT", {
                    "default": 255,
                    "min": 0,
                    "max": 255,
                    "step": 1,
                    "tooltip": "å­—ä½“çº¢è‰²åˆ†é‡"
                }),
                "font_color_g": ("INT", {
                    "default": 255,
                    "min": 0,
                    "max": 255,
                    "step": 1,
                    "tooltip": "å­—ä½“ç»¿è‰²åˆ†é‡"
                }),
                "font_color_b": ("INT", {
                    "default": 255,
                    "min": 0,
                    "max": 255,
                    "step": 1,
                    "tooltip": "å­—ä½“è“è‰²åˆ†é‡"
                }),
                "enable_shadow": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "æ˜¯å¦å¯ç”¨å­—å¹•é˜´å½±"
                }),
                "language_hint": ("STRING", {
                    "default": "",
                    "multiline": False,
                    "placeholder": "è¯­è¨€æç¤º(å¦‚:zh,en)ï¼Œç•™ç©ºè‡ªåŠ¨æ£€æµ‹",
                    "tooltip": "æŒ‡å®šéŸ³é¢‘è¯­è¨€ä»¥æé«˜è¯†åˆ«å‡†ç¡®åº¦"
                })
            }
        }
    
    RETURN_TYPES = ("STRING", "STRING", "STRING", "STRING")
    RETURN_NAMES = ("output_video_path", "subtitle_file_path", "transcription_text", "error_msg")
    FUNCTION = "process_video"
    CATEGORY = "Video/Subtitle"
    OUTPUT_NODE = True
    
    def _build_ui_output(self, output_video_path: str, srt_path: str, transcription_text: str, error_msg: str):
        """å°†å…³é”®ç»“æœæš´éœ²åˆ° Comfy çš„ UI è¾“å‡ºï¼Œä»¥ä¾¿ API è¿”å›çš„ outputs èƒ½è¯»å–ã€‚
        æ–‡æœ¬æ”¾åœ¨ ui['text']ï¼Œæ–‡ä»¶ä»¥ç±»ä¼¼ SaveImage çš„ç»“æ„æ”¾åœ¨ ui['files']ã€‚
        """
        ui_text_items = []
        ui_files = []
        if len(output_video_path) > 0:
            ui_text_items.append({"title": "output_video_path", "content": output_video_path})
            ui_files.append({
                "filename": os.path.basename(output_video_path),
                "subfolder": os.path.dirname(output_video_path),
                "type": "output",
            })
        else:
            ui_text_items.append({"title": "output_video_path", "content": "None"})
        if len(srt_path) > 0:
            ui_text_items.append({"title": "subtitle_file_path", "content": srt_path})
            ui_files.append({
                "filename": os.path.basename(srt_path),
                "subfolder": os.path.dirname(srt_path),
                "type": "subtitle",
            })
        else:
            ui_text_items.append({"title": "subtitle_file_path", "content": "None"})

        if len(transcription_text) > 0:
            ui_text_items.append({"title": "transcription_text", "content": transcription_text})
        else:
            ui_text_items.append({"title": "transcription_text", "content": "None"})

        if len(error_msg) > 0:
            ui_text_items.append({"title": "error_msg", "content": error_msg})
        else:
            ui_text_items.append({"title": "error_msg", "content": "None"})

        ui = {}
        ui["text"] = ui_text_items
        ui["files"] = ui_files
        return ui

    def process_video(self, whisper_model: WhisperService, video_path: str, 
                     output_prefix: str, subtitle_style: str, **kwargs) -> Tuple[str, str, str, str]:
        """
        å¤„ç†è§†é¢‘æ·»åŠ å­—å¹•ï¼ˆä½¿ç”¨é¢„åŠ è½½æ¨¡å‹ï¼‰
        
        Args:
            whisper_model: é¢„åŠ è½½çš„Whisperæ¨¡å‹æœåŠ¡
            video_path: è¾“å…¥è§†é¢‘è·¯å¾„
            output_prefix: è¾“å‡ºç›®å½•å‰ç¼€(æ‹¼æ¥åˆ°ComfyUIè¾“å‡ºç›®å½•å)
            subtitle_style: å­—å¹•æ ·å¼
            **kwargs: å¯é€‰å‚æ•°
            
        Returns:
            (è¾“å‡ºè§†é¢‘è·¯å¾„, å­—å¹•æ–‡ä»¶è·¯å¾„, è½¬å½•æ–‡æœ¬, å¤„ç†æ—¥å¿—)
        """
        try:
            # éªŒè¯æ¨¡å‹
            if whisper_model is None:
                error_msg = "âŒ Whisperæ¨¡å‹æœªåŠ è½½æˆ–åŠ è½½å¤±è´¥,è¯·å…ˆä½¿ç”¨Whisperæ¨¡å‹åŠ è½½èŠ‚ç‚¹"
                return {
                    "ui": self._build_ui_output("", "", "", error_msg),
                    "result": ("", "", "", error_msg)
                }
            
            # éªŒè¯è¾“å…¥æ–‡ä»¶
            if not os.path.exists(video_path):
                error_msg = f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}"
                return {
                    "ui": self._build_ui_output("", "", "", error_msg),
                    "result": ("", "", "", error_msg)
                }
            
            # è·å–ComfyUIè¾“å‡ºç›®å½•å¹¶æ‹¼æ¥å‰ç¼€
            if folder_paths is not None:
                comfy_output_dir = folder_paths.get_output_directory()
                output_dir = os.path.join(comfy_output_dir, output_prefix)
            else:
                # å¦‚æœä¸åœ¨ComfyUIç¯å¢ƒä¸­ï¼Œä½¿ç”¨é»˜è®¤è¾“å‡ºç›®å½•
                output_dir = os.path.join("./output", output_prefix)
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            os.makedirs(output_dir, exist_ok=True)
            
            # è®¾ç½®æ—¥å¿—è®°å½•
            # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶åï¼ˆä½¿ç”¨æ—¶é—´æˆ³é¿å…å†²çªï¼‰
            video_name = os.path.splitext(os.path.basename(video_path))[0]
            timestamp = int(time.time())
            unique_suffix = f"_{timestamp}"
            
            audio_path = os.path.join(output_dir, f"{video_name}{unique_suffix}.wav")
            srt_path = os.path.join(output_dir, f"{video_name}{unique_suffix}.srt")
            output_video_path = os.path.join(output_dir, f"{video_name}{unique_suffix}_with_subtitles.mp4")
            
            # æ­¥éª¤1: ä»è§†é¢‘ä¸­æå–éŸ³é¢‘
            print("ğŸµ æ­¥éª¤1: æå–éŸ³é¢‘...")
            if not self.audio_service.extract_audio_from_video(video_path, audio_path):
                error_msg = "âŒ éŸ³é¢‘æå–å¤±è´¥"
                return {
                    "ui": self._build_ui_output("", "", "", error_msg),
                    "result": ("", "", "", error_msg)
                }
            
            # éªŒè¯éŸ³é¢‘æ–‡ä»¶
            if not self.audio_service.validate_audio_file(audio_path):
                error_msg = "âŒ éŸ³é¢‘æ–‡ä»¶éªŒè¯å¤±è´¥"
                return {
                    "ui": self._build_ui_output("", "", "", error_msg),
                    "result": ("", "", "", error_msg)
                }
            
            # æ­¥éª¤2: ä½¿ç”¨é¢„åŠ è½½çš„Whisperæ¨¡å‹è¿›è¡Œè¯­éŸ³è¯†åˆ«ï¼ˆæ”¯æŒè¯çº§æˆ–è¡Œçº§è¾“å‡ºï¼‰
            print("ğŸ™ï¸ æ­¥éª¤2: è¯­éŸ³è¯†åˆ«...")

            # ä½¿ç”¨é¢„åŠ è½½æ¨¡å‹ç›´æ¥è½¬å½•
            if hasattr(whisper_model, '_model') and whisper_model._model is not None:
                try:
                    # å¯ç”¨è¯çº§æ—¶é—´æˆ³ï¼Œä¾¿äºä¸¤ç§æ¨¡å¼çš„æ—¶é—´è®¡ç®—
                    segments, info = whisper_model._model.transcribe(
                        audio_path,
                        beam_size=5,
                        word_timestamps=True
                    )

                    # æ ¹æ®è¾“å‡ºæ¨¡å¼ç»„è£…å­—å¹•æ¡ç›®
                    output_mode = kwargs.get("output_mode", "line")
                    max_chars_per_line = kwargs.get("max_chars_per_line", 30)
                    transcript_lines = []
                    full_text = ""

                    # ç®€æ˜“çš„ä¸­è‹±æ–‡æ ‡ç‚¹é›†åˆ
                    punctuation_chars = set(
                        list(",.!?;:") + list("ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šã€")
                    )

                    def needs_space(prev_char: str, next_char: str) -> bool:
                        import re
                        return bool(re.match(r"[A-Za-z0-9]", prev_char or "")) and bool(re.match(r"[A-Za-z0-9]", next_char or ""))

                    if output_mode == "word":
                        # æ¯ä¸ªè¯ä¸€æ¡
                        for segment in segments:
                            if hasattr(segment, 'words') and segment.words:
                                for w in segment.words:
                                    word_text = (w.word or "").strip()
                                    if not word_text:
                                        continue
                                    transcript_lines.append(
                                        f"[{getattr(w, 'start', segment.start):.2f}s -> {getattr(w, 'end', segment.end):.2f}s] {word_text}"
                                    )
                                    full_text += word_text + " "
                            else:
                                transcript_lines.append(
                                    f"[{segment.start:.2f}s -> {segment.end:.2f}s] {segment.text}"
                                )
                                full_text += (segment.text or "") + " "
                    else:
                        # line: æŒ‰æ ‡ç‚¹æ¢è¡Œï¼Œå°†è¯åˆå¹¶ä¸ºå¥å­
                        for segment in segments:
                            if hasattr(segment, 'words') and segment.words:
                                line_start = None
                                line_text = ""
                                last_char = ""
                                last_word_end = None

                                for w in segment.words:
                                    word_text_raw = (w.word or "")
                                    word_text = word_text_raw.strip()
                                    if not word_text:
                                        continue

                                    if line_start is None:
                                        line_start = getattr(w, 'start', segment.start)

                                    # æ‹¼æ¥æ—¶ä¸­è‹±æ–‡é—´è‡ªåŠ¨åŠ ç©ºæ ¼ï¼ˆä»…è‹±æ–‡å­—æ¯/æ•°å­—ä¹‹é—´ï¼‰
                                    pending = word_text
                                    add_space = line_text and needs_space(last_char[-1:] if last_char else "", word_text[:1] if word_text else "")
                                    candidate_text = (line_text + (" " if add_space else "") + pending) if line_text else pending

                                    # å­—ç¬¦é•¿åº¦é™åˆ¶ï¼šè¶…è¿‡åˆ™ä»¥ä¸Šä¸€è¯ç»“æŸæ—¶é—´æ–­å¼€
                                    if line_text and len(candidate_text) > max_chars_per_line and last_word_end is not None:
                                        line_text, line_start = flush_line(line_text, line_start, last_word_end, transcript_lines)
                                        # æ–­è¡Œåé‡æ–°å¼€å§‹æœ¬è¯
                                        line_start = getattr(w, 'start', segment.start)
                                        line_text = pending
                                    else:
                                        # æ¥å—è¿½åŠ 
                                        if add_space:
                                            line_text += " "
                                        line_text += pending
                                    last_char = pending

                                    # ç¢°åˆ°æ ‡ç‚¹åˆ™æ¢è¡Œ
                                    ending_char = word_text[-1]
                                    if ending_char in punctuation_chars:
                                        end_time = getattr(w, 'end', segment.end)
                                        line_text, line_start = flush_line(line_text, line_start, end_time, transcript_lines)
                                        last_word_end = end_time
                                        continue

                                    # è®°å½•å½“å‰è¯ç»“æŸæ—¶é—´ï¼Œç”¨äºåç»­é•¿åº¦æ–­è¡Œæˆ–æ”¶å°¾
                                    last_word_end = getattr(w, 'end', segment.end)

                                # å¤„ç†æ®‹ç•™è¡Œ
                                if line_text and line_start is not None:
                                    end_time = last_word_end if last_word_end is not None else getattr(segment.words[-1], 'end', segment.end)
                                    line_text, line_start = flush_line(line_text, line_start, end_time, transcript_lines)
                            else:
                                # æ— è¯çº§åˆ«ä¿¡æ¯æ—¶ï¼Œæ•´æ®µä½œä¸ºä¸€è¡Œ
                                transcript_lines.append(
                                    f"[{segment.start:.2f}s -> {segment.end:.2f}s] {segment.text}"
                                )
                                
                            # æ±‡æ€»å…¨æ–‡
                            full_text += (segment.text or "") + " "

                    whisper_result = {
                        'language': info.language,
                        'language_probability': info.language_probability,
                        'segments': transcript_lines,
                        'full_text': full_text.strip()
                    }

                except Exception as e:
                    error_msg = f"âŒ æ¨¡å‹è½¬å½•å¤±è´¥: {str(e)}"
                    return {
                        "ui": self._build_ui_output("", "", "", error_msg),
                        "result": ("", "", "", error_msg)
                    }
            else:
                error_msg = "âŒ æ¨¡å‹æœªæ­£ç¡®åŠ è½½"
                return {
                    "ui": self._build_ui_output("", "", "", error_msg),
                    "result": ("", "", "", error_msg)
                }
            
            if not whisper_result:
                error_msg = "âŒ è¯­éŸ³è¯†åˆ«å¤±è´¥"
                return {
                    "ui": self._build_ui_output("", "", "", error_msg),
                    "result": ("", "", "", error_msg)
                }
            
            # è¾“å‡ºè¯†åˆ«ä¿¡æ¯
            language = whisper_result.get('language', 'unknown')
            language_name = whisper_model.get_language_name(language)
            confidence = whisper_result.get('language_probability', 0)
            full_text = whisper_result.get('full_text', '')
            
            print(f"âœ… è¯†åˆ«è¯­è¨€: {language_name} (ç½®ä¿¡åº¦: {confidence:.2f})")
            print(f"ğŸ“ è¯†åˆ«åˆ° {len(whisper_result['segments'])} ä¸ªè¯­éŸ³æ®µè½")
            
            # æ­¥éª¤3: ç”ŸæˆSRTå­—å¹•æ–‡ä»¶
            print("ğŸ“„ æ­¥éª¤3: ç”Ÿæˆå­—å¹•æ–‡ä»¶...")
            if not self.subtitle_service.generate_srt_from_whisper_result(whisper_result, srt_path):
                error_msg = "âŒ å­—å¹•æ–‡ä»¶ç”Ÿæˆå¤±è´¥"
                return {
                    "ui": self._build_ui_output("", "", "", error_msg),
                    "result": ("", "", "", error_msg)
                }
            
            # éªŒè¯å­—å¹•æ–‡ä»¶
            if not self.subtitle_service.validate_srt_file(srt_path):
                error_msg = "âŒ å­—å¹•æ–‡ä»¶éªŒè¯å¤±è´¥"
                return {
                    "ui": self._build_ui_output("", srt_path, full_text, error_msg),
                    "result": ("", srt_path, full_text, error_msg)
                }
            
            # è¾“å‡ºå­—å¹•ä¿¡æ¯
            subtitle_info = self.subtitle_service.get_subtitle_info(srt_path)
            if subtitle_info:
                print(f"ğŸ“Š å­—å¹•æ¡ç›®æ•°: {subtitle_info['entry_count']}")
                print(f"ğŸ“ å­—å¹•æ–‡ä»¶å¤§å°: {subtitle_info['file_size']} å­—èŠ‚")
            
            # å¤„ç†è‡ªå®šä¹‰æ ·å¼
            custom_style = self._create_custom_style(subtitle_style, **kwargs)
            
            # æ­¥éª¤4: å°†å­—å¹•åµŒå…¥è§†é¢‘
            print("ğŸ¬ æ­¥éª¤4: åµŒå…¥å­—å¹•...")
            
            # ç¡®å®šä½¿ç”¨çš„å­—å¹•æ ·å¼
            if custom_style:
                # ä½¿ç”¨è‡ªå®šä¹‰æ ·å¼
                if not self.video_service.embed_subtitles(video_path, srt_path, output_video_path, custom_style):
                    error_msg = "âŒ å­—å¹•åµŒå…¥å¤±è´¥"
                    return {
                        "ui": self._build_ui_output("", srt_path, full_text, error_msg),
                        "result": ("", srt_path, full_text, error_msg)
                    }
            else:
                # ä½¿ç”¨é¢„è®¾æ ·å¼
                if not self.video_service.embed_subtitles_with_preset(video_path, srt_path, output_video_path, subtitle_style):
                    error_msg = "âŒ å­—å¹•åµŒå…¥å¤±è´¥"
                    return {
                        "ui": self._build_ui_output("", srt_path, full_text, error_msg),
                        "result": ("", srt_path, full_text, error_msg)
                    }
            
            # è·å–è¾“å‡ºè§†é¢‘ä¿¡æ¯
            video_info = self.video_service.get_video_info_local(output_video_path)
            if video_info:
                duration = video_info.get('duration', 0)
                size_mb = video_info.get('size', 0) / (1024 * 1024)
                print(f"â±ï¸ è¾“å‡ºè§†é¢‘æ—¶é•¿: {duration:.2f}ç§’")
                print(f"ğŸ’¾ è¾“å‡ºè§†é¢‘å¤§å°: {size_mb:.2f}MB")
            
            print("ğŸ‰ å¤„ç†å®Œæˆï¼è¾“å‡ºæ–‡ä»¶:")
            print(f"  ğŸ“¹ å¸¦å­—å¹•è§†é¢‘: {output_video_path}")
            print(f"  ğŸ“„ å­—å¹•æ–‡ä»¶: {srt_path}")
            
            # æ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
            try:
                os.remove(audio_path)
                print("ğŸ§¹ ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶å·²æ¸…ç†")
            except:
                pass
            
            # è¿”å› UI + ç»“æœï¼ŒUI ç”¨äº API ç›´æ¥è¯»å–
            return {
                "ui": self._build_ui_output(output_video_path, srt_path, full_text, ""),
                "result": (output_video_path, srt_path, full_text, "")
            }
            
        except Exception as e:
            error_msg = f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
            return {
                "ui": self._build_ui_output("", "", "", error_msg),
                "result": ("", "", "", error_msg)
            }
    
    def _create_custom_style(self, base_style_name: str, **kwargs):
        """
        åˆ›å»ºè‡ªå®šä¹‰æ ·å¼
        
        Args:
            base_style_name: åŸºç¡€æ ·å¼åç§°
            **kwargs: è‡ªå®šä¹‰å‚æ•°
            
        Returns:
            è‡ªå®šä¹‰æ ·å¼å¯¹è±¡æˆ–None
        """
        custom_font_size = kwargs.get("custom_font_size", 24)
        custom_position = kwargs.get("custom_position", "none")
        font_color_r = kwargs.get("font_color_r", 255)
        font_color_g = kwargs.get("font_color_g", 255)
        font_color_b = kwargs.get("font_color_b", 255)
        enable_shadow = kwargs.get("enable_shadow", True)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è‡ªå®šä¹‰è®¾ç½®
        if any([
            custom_position != "none",
            custom_font_size != 24,
            (font_color_r, font_color_g, font_color_b) != (255, 255, 255),
            enable_shadow is not True
        ]):
            # åˆ›å»ºè‡ªå®šä¹‰æ ·å¼
            base_style = PresetStyles.default()
            
            # åº”ç”¨è‡ªå®šä¹‰è®¾ç½®
            if custom_position != "none":
                base_style.position = SubtitlePosition(custom_position)
            
            if custom_font_size != 24:
                base_style.font_size = custom_font_size
            
            # è‡ªå®šä¹‰é¢œè‰²
            if (font_color_r, font_color_g, font_color_b) != (255, 255, 255):
                base_style.font_color = (font_color_r, font_color_g, font_color_b)
            
            # é˜´å½±è®¾ç½®
            base_style.shadow_enabled = enable_shadow
            
            return base_style
        
        return None


class LogHandler(logging.Handler):
    """è‡ªå®šä¹‰æ—¥å¿—å¤„ç†å™¨ï¼Œç”¨äºæ”¶é›†æ—¥å¿—æ¶ˆæ¯"""
    
    def __init__(self, log_messages):
        super().__init__()
        self.log_messages = log_messages
    
    def emit(self, record):
        msg = self.format(record)
        # è¿‡æ»¤æ‰ä¸€äº›ä¸å¿…è¦çš„æ—¥å¿—
        if any(skip in msg for skip in ['faster_whisper', 'Processing audio']):
            return
        self.log_messages.append(msg)


# ComfyUIèŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "VideoSubtitleWithModelNode": VideoSubtitleWithModelNode
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "VideoSubtitleWithModelNode": "ğŸ¬ Video Subtitle (with Model)"
}

# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("ğŸ§ª æµ‹è¯•è§†é¢‘å­—å¹•èŠ‚ç‚¹ï¼ˆé¢„åŠ è½½æ¨¡å‹ç‰ˆæœ¬ï¼‰...")
    
    # å…ˆæµ‹è¯•Whisperæ¨¡å‹åŠ è½½
    from whisper_model_node import WhisperModelNode
    
    model_node = WhisperModelNode()
    whisper_service, model_info = model_node.load_model("small", "cuda", "float16")
    
    print("ğŸ“‹ æ¨¡å‹åŠ è½½ç»“æœ:")
    print(model_info)
    
    if whisper_service and os.path.exists("test.mp4"):
        # æµ‹è¯•è§†é¢‘å­—å¹•ç”Ÿæˆ
        subtitle_node = VideoSubtitleWithModelNode()
        
        output_video, subtitle_file, transcription, log = subtitle_node.process_video(
            whisper_model=whisper_service,
            video_path="test.mp4",
            output_prefix="test_with_model_output",
            subtitle_style="strong_shadow"
        )
        
        print("\nğŸ“‹ å­—å¹•ç”Ÿæˆç»“æœ:")
        print(f"è¾“å‡ºè§†é¢‘: {output_video}")
        print(f"å­—å¹•æ–‡ä»¶: {subtitle_file}")
        print(f"è½¬å½•æ–‡æœ¬: {transcription[:100]}...")
        print(f"\nå¤„ç†æ—¥å¿—:\n{log}")
    
    print("\nâœ… æµ‹è¯•å®Œæˆ!")