"""
ComfyUIè‡ªå®šä¹‰èŠ‚ç‚¹ï¼šæ–‡æœ¬è¦†ç›–è§†é¢‘èŠ‚ç‚¹
ä¸ºè§†é¢‘æ·»åŠ è‡ªå®šä¹‰æ–‡æœ¬è¦†ç›–åŠŸèƒ½
"""

import os
import sys
import logging
import tempfile
import time
from typing import Dict, Any, Tuple
from datetime import datetime

# æ·»åŠ çˆ¶ç›®å½•åˆ°Pythonè·¯å¾„ä»¥æ”¯æŒå¯¼å…¥
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

try:
    from ..services.text_overlay_service import TextOverlayService, TextOverlayStyle, TextAlignment
except ImportError:
    from services.text_overlay_service import TextOverlayService, TextOverlayStyle, TextAlignment


class ProgressLogger:
    """è¿›åº¦æ—¥å¿—è®°å½•å™¨"""
    
    def __init__(self, task_name: str):
        self.task_name = task_name
        self.start_time = time.time()
        self.last_update = self.start_time
        
    def log_progress(self, step: str, detail: str = "", progress_percent: float = None):
        """è®°å½•è¿›åº¦ä¿¡æ¯"""
        current_time = time.time()
        elapsed = current_time - self.start_time
        
        # æ ¼å¼åŒ–è¾“å‡º
        timestamp = datetime.now().strftime("%H:%M:%S")
        
        if progress_percent is not None:
            progress_bar = self._create_progress_bar(progress_percent)
            print(f"\033[32m[{timestamp}]\033[0m \033[36m{self.task_name}\033[0m - {step}")
            print(f"         {progress_bar} {progress_percent:.1f}%")
            if detail:
                print(f"         ğŸ“ {detail}")
        else:
            print(f"\033[32m[{timestamp}]\033[0m \033[36m{self.task_name}\033[0m - ğŸ”„ {step}")
            if detail:
                print(f"         ğŸ“ {detail}")
        
        print(f"         â±ï¸  å·²ç”¨æ—¶: {elapsed:.1f}ç§’")
        print()  # ç©ºè¡Œåˆ†éš”
        
    def log_success(self, message: str):
        """è®°å½•æˆåŠŸä¿¡æ¯"""
        elapsed = time.time() - self.start_time
        timestamp = datetime.now().strftime("%H:%M:%S")
        print(f"\033[32m[{timestamp}]\033[0m \033[36m{self.task_name}\033[0m - âœ… {message}")
        print(f"         â±ï¸  æ€»ç”¨æ—¶: {elapsed:.1f}ç§’")
        print()
        
    def log_error(self, message: str):
        """è®°å½•é”™è¯¯ä¿¡æ¯"""
        elapsed = time.time() - self.start_time
        timestamp = datetime.now().strftime("%H:%M:%S")
        print(f"\033[31m[{timestamp}]\033[0m \033[36m{self.task_name}\033[0m - âŒ {message}")
        print(f"         â±ï¸  ç”¨æ—¶: {elapsed:.1f}ç§’")
        print()
        
    def _create_progress_bar(self, percent: float, width: int = 30) -> str:
        """åˆ›å»ºè¿›åº¦æ¡"""
        filled = int(width * percent / 100)
        bar = "â–ˆ" * filled + "â–‘" * (width - filled)
        return f"[{bar}]"


class TextOverlayVideoNode:
    """ComfyUIæ–‡æœ¬è¦†ç›–è§†é¢‘èŠ‚ç‚¹"""
    
    def __init__(self):
        self.service = TextOverlayService()
        self.setup_logging()
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—é…ç½®"""
        # é…ç½®ç»ˆç«¯æ—¥å¿—è¾“å‡º
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            force=True
        )
        self.logger = logging.getLogger(f"TextOverlay_{id(self)}")
    
    def get_color_rgb(self, color_name: str) -> tuple:
        """å°†é¢œè‰²åç§°è½¬æ¢ä¸ºRGBå€¼"""
        color_map = {
            # ä¸­æ–‡é¢œè‰²åç§°æ˜ å°„
            "é»‘è‰²": (0, 0, 0),
            "ç™½è‰²": (255, 255, 255),
            "çº¢è‰²": (255, 0, 0),
            "ç»¿è‰²": (0, 255, 0),
            "è“è‰²": (0, 0, 255),
            "é»„è‰²": (255, 255, 0),
            "é’è‰²": (0, 255, 255),
            "æ´‹çº¢": (255, 0, 255),
            "æ©™è‰²": (255, 165, 0),
            "ç´«è‰²": (128, 0, 128),
            "ç°è‰²": (128, 128, 128),
            "æ·±ç°": (64, 64, 64),
            "æµ…ç°": (192, 192, 192),
            "é€æ˜": (0, 0, 0),  # é€æ˜èƒŒæ™¯ç”¨é»‘è‰²ï¼Œä½†ä¼šè®¾ç½®ä¸ºå®Œå…¨é€æ˜
            # å…¼å®¹è‹±æ–‡åç§°ï¼ˆå‘ä¸‹å…¼å®¹ï¼‰
            "black": (0, 0, 0),
            "white": (255, 255, 255),
            "red": (255, 0, 0),
            "green": (0, 255, 0),
            "blue": (0, 0, 255),
            "yellow": (255, 255, 0),
            "cyan": (0, 255, 255),
            "magenta": (255, 0, 255),
            "orange": (255, 165, 0),
            "purple": (128, 0, 128),
            "gray": (128, 128, 128),
            "darkgray": (64, 64, 64),
            "lightgray": (192, 192, 192),
            "transparent": (0, 0, 0)
        }
        return color_map.get(color_name, (0, 0, 0))
    
    def get_position_preset(self, position_name: str) -> str:
        """å°†ä¸­æ–‡ä½ç½®åç§°è½¬æ¢ä¸ºè‹±æ–‡é¢„è®¾åç§°"""
        position_map = {
            "åº•éƒ¨å±…ä¸­": "bottom",
            "åº•éƒ¨åä¸‹": "bottom_low", 
            "åº•éƒ¨åä¸Š": "bottom_high",
            "å±å¹•ä¸­å¤®": "center",
            "ä¸­å¤®åä¸‹": "center_low",
            "ä¸­å¤®åä¸Š": "center_high",
            "é¡¶éƒ¨å±…ä¸­": "top",
            "é¡¶éƒ¨åä¸‹": "top_low",
            "é¡¶éƒ¨åä¸Š": "top_high",
            # å…¼å®¹è‹±æ–‡åç§°ï¼ˆå‘ä¸‹å…¼å®¹ï¼‰
            "bottom": "bottom",
            "bottom_low": "bottom_low",
            "bottom_high": "bottom_high",
            "center": "center",
            "center_low": "center_low",
            "center_high": "center_high",
            "top": "top",
            "top_low": "top_low",
            "top_high": "top_high"
        }
        return position_map.get(position_name, "bottom")
    
    def get_text_alignment(self, alignment_name: str) -> str:
        """å°†ä¸­æ–‡å¯¹é½æ–¹å¼è½¬æ¢ä¸ºè‹±æ–‡"""
        alignment_map = {
            "å±…ä¸­": "center",
            "å·¦å¯¹é½": "left",
            "å³å¯¹é½": "right",
            # å…¼å®¹è‹±æ–‡åç§°ï¼ˆå‘ä¸‹å…¼å®¹ï¼‰
            "center": "center",
            "left": "left",
            "right": "right"
        }
        return alignment_map.get(alignment_name, "center")
    
    def wrap_text(self, text: str, max_chars_per_line: int) -> str:
        """
        æ–‡æœ¬è‡ªåŠ¨æ¢è¡Œå¤„ç†
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            max_chars_per_line: æ¯è¡Œæœ€å¤§å­—ç¬¦æ•°
            
        Returns:
            å¤„ç†åçš„æ–‡æœ¬ï¼ˆåŒ…å«æ¢è¡Œç¬¦ï¼‰
        """
        if not text:
            return text
            
        # å…ˆå¤„ç†å·²æœ‰çš„æ¢è¡Œç¬¦
        lines = text.split('\n')
        wrapped_lines = []
        
        for line in lines:
            if len(line) <= max_chars_per_line:
                wrapped_lines.append(line)
                continue
                
            # å¯¹é•¿è¡Œè¿›è¡Œå¤„ç†
            current_line = ""
            words = line.split(' ')
            
            for word in words:
                # å¦‚æœå•ä¸ªå•è¯å°±è¶…è¿‡äº†æœ€å¤§é•¿åº¦ï¼Œå¼ºåˆ¶æ–­å¼€
                if len(word) > max_chars_per_line:
                    # å…ˆæ·»åŠ å½“å‰è¡Œï¼ˆå¦‚æœæœ‰å†…å®¹ï¼‰
                    if current_line:
                        wrapped_lines.append(current_line.strip())
                        current_line = ""
                    
                    # å¼ºåˆ¶æ–­å¼€é•¿å•è¯
                    for i in range(0, len(word), max_chars_per_line):
                        chunk = word[i:i + max_chars_per_line]
                        wrapped_lines.append(chunk)
                    continue
                
                # æ£€æŸ¥æ·»åŠ è¿™ä¸ªå•è¯åæ˜¯å¦ä¼šè¶…è¿‡é™åˆ¶
                test_line = current_line + (" " if current_line else "") + word
                
                if len(test_line) <= max_chars_per_line:
                    current_line = test_line
                else:
                    # å½“å‰è¡Œå·²æ»¡ï¼Œå¼€å§‹æ–°è¡Œ
                    if current_line:
                        wrapped_lines.append(current_line.strip())
                    current_line = word
            
            # æ·»åŠ æœ€åä¸€è¡Œ
            if current_line:
                wrapped_lines.append(current_line.strip())
        
        return '\n'.join(wrapped_lines)
    
    def get_text_stats(self, text: str) -> dict:
        """
        è·å–æ–‡æœ¬ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            text: æ–‡æœ¬å†…å®¹
            
        Returns:
            æ–‡æœ¬ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        lines = text.split('\n')
        return {
            'total_chars': len(text),
            'total_lines': len(lines),
            'max_line_length': max(len(line) for line in lines) if lines else 0,
            'avg_line_length': sum(len(line) for line in lines) / len(lines) if lines else 0
        }
        
    @classmethod
    def INPUT_TYPES(cls):
        """å®šä¹‰èŠ‚ç‚¹è¾“å…¥ç±»å‹"""
        return {
            "required": {
                "images": ("IMAGE", {
                    "tooltip": "è¾“å…¥å›¾åƒåºåˆ—ï¼ˆæ¥è‡ªè§†é¢‘æˆ–å›¾åƒå¤„ç†èŠ‚ç‚¹ï¼‰"
                }),
                "text_content": ("STRING", {
                    "default": "åœ¨è¿™é‡Œè¾“å…¥æ–‡æœ¬å†…å®¹",
                    "multiline": True,
                    "placeholder": "è¦æ˜¾ç¤ºåœ¨è§†é¢‘ä¸Šçš„æ–‡æœ¬"
                }),
                "position": ([
                    "åº•éƒ¨å±…ä¸­",          # bottom
                    "åº•éƒ¨åä¸‹",          # bottom_low
                    "åº•éƒ¨åä¸Š",          # bottom_high
                    "å±å¹•ä¸­å¤®",          # center
                    "ä¸­å¤®åä¸‹",          # center_low
                    "ä¸­å¤®åä¸Š",          # center_high
                    "é¡¶éƒ¨å±…ä¸­",          # top
                    "é¡¶éƒ¨åä¸‹",          # top_low
                    "é¡¶éƒ¨åä¸Š"           # top_high
                ], {
                    "default": "åº•éƒ¨å±…ä¸­",
                    "tooltip": "æ–‡æœ¬åœ¨è§†é¢‘ä¸­çš„å‚ç›´ä½ç½®ï¼ˆæ°´å¹³æ–¹å‘å§‹ç»ˆå±…ä¸­ï¼‰"
                }),
                "font_size": ("INT", {
                    "default": 24,
                    "min": 12,
                    "max": 72,
                    "step": 1,
                    "tooltip": "å­—ä½“å¤§å°ï¼ˆåƒç´ ï¼‰"
                }),
                "font_color": ([
                    "é»‘è‰²",          # black
                    "ç™½è‰²",          # white
                    "çº¢è‰²",          # red
                    "ç»¿è‰²",          # green
                    "è“è‰²",          # blue
                    "é»„è‰²",          # yellow
                    "é’è‰²",          # cyan
                    "æ´‹çº¢",          # magenta
                    "æ©™è‰²",          # orange
                    "ç´«è‰²",          # purple
                    "ç°è‰²",          # gray
                    "æ·±ç°"           # darkgray
                ], {
                    "default": "é»‘è‰²",
                    "tooltip": "å­—ä½“é¢œè‰²é¢„è®¾"
                }),
                "background_color": ([
                    "ç™½è‰²",          # white
                    "é»‘è‰²",          # black
                    "é€æ˜",          # transparent
                    "çº¢è‰²",          # red
                    "ç»¿è‰²",          # green
                    "è“è‰²",          # blue
                    "é»„è‰²",          # yellow
                    "é’è‰²",          # cyan
                    "æ´‹çº¢",          # magenta
                    "æ©™è‰²",          # orange
                    "ç´«è‰²",          # purple
                    "ç°è‰²",          # gray
                    "æµ…ç°"           # lightgray
                ], {
                    "default": "ç™½è‰²",
                    "tooltip": "èƒŒæ™¯é¢œè‰²é¢„è®¾"
                }),
                "background_opacity": ("FLOAT", {
                    "default": 0.8,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.1,
                    "tooltip": "èƒŒæ™¯é€æ˜åº¦ï¼ˆ0=å®Œå…¨é€æ˜ï¼Œ1=å®Œå…¨ä¸é€æ˜ï¼‰"
                }),
                "max_chars_per_line": ("INT", {
                    "default": 30,
                    "min": 10,
                    "max": 100,
                    "step": 1,
                    "tooltip": "æ¯è¡Œæœ€å¤§å­—ç¬¦æ•°ï¼ˆè¶…è¿‡è‡ªåŠ¨æ¢è¡Œï¼‰"
                })
            },
            "optional": {
                "enable_background": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "æ˜¯å¦å¯ç”¨æ–‡å­—èƒŒæ™¯"
                }),
                "font_bold": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "æ˜¯å¦ä½¿ç”¨ç²—ä½“å­—"
                }),
                "text_alignment": ([
                    "å±…ä¸­",        # center
                    "å·¦å¯¹é½",      # left
                    "å³å¯¹é½"       # right
                ], {
                    "default": "å±…ä¸­",
                    "tooltip": "æ–‡æœ¬å¯¹é½æ–¹å¼"
                }),
                "enable_shadow": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "æ˜¯å¦å¯ç”¨æ–‡å­—é˜´å½±"
                }),
                "enable_border": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "æ˜¯å¦å¯ç”¨æ–‡å­—è¾¹æ¡†"
                }),
                "margin_x": ("INT", {
                    "default": 50,
                    "min": 0,
                    "max": 200,
                    "step": 5,
                    "tooltip": "æ°´å¹³è¾¹è·ï¼ˆåƒç´ ï¼‰"
                }),
                "margin_y": ("INT", {
                    "default": 50,
                    "min": 0,
                    "max": 200,
                    "step": 5,
                    "tooltip": "å‚ç›´è¾¹è·ï¼ˆåƒç´ ï¼‰"
                })
            }
        }
    
    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("images", "processing_log")
    FUNCTION = "process_text_overlay"
    CATEGORY = "Video/Text"
    OUTPUT_NODE = False
    
    def process_text_overlay(self, images, text_content: str, position: str, 
                           font_size: int, font_color: str, background_color: str,
                           background_opacity: float, max_chars_per_line: int, **kwargs) -> Tuple[Any, str]:
        """
        å¤„ç†æ–‡æœ¬è¦†ç›–
        
        Args:
            images: è¾“å…¥å›¾åƒåºåˆ—
            text_content: æ–‡æœ¬å†…å®¹
            position: ä½ç½®
            font_size: å­—ä½“å¤§å°
            font_color: å­—ä½“é¢œè‰²é¢„è®¾
            background_color: èƒŒæ™¯é¢œè‰²é¢„è®¾
            background_opacity: èƒŒæ™¯é€æ˜åº¦
            max_chars_per_line: æ¯è¡Œæœ€å¤§å­—ç¬¦æ•°
            **kwargs: å…¶ä»–å¯é€‰å‚æ•°
            
        Returns:
            (å¤„ç†åçš„å›¾åƒåºåˆ—, å¤„ç†æ—¥å¿—)
        """
        # åˆ›å»ºè¿›åº¦è®°å½•å™¨
        progress = ProgressLogger("æ–‡æœ¬è¦†ç›–å¤„ç†")
        
        # åœ¨ç»ˆç«¯æ˜¾ç¤ºå¼€å§‹ä¿¡æ¯
        print("\n" + "="*60)
        print("ğŸ¬ ComfyUIæ–‡æœ¬è¦†ç›–è§†é¢‘èŠ‚ç‚¹å¼€å§‹å¤„ç†")
        print("="*60)
        
        try:
            # è·å–å¯é€‰å‚æ•°
            enable_background = kwargs.get("enable_background", True)
            font_bold = kwargs.get("font_bold", False)
            text_alignment_cn = kwargs.get("text_alignment", "å±…ä¸­")
            enable_shadow = kwargs.get("enable_shadow", False)
            enable_border = kwargs.get("enable_border", False)
            margin_x = kwargs.get("margin_x", 50)
            margin_y = kwargs.get("margin_y", 50)
            
            log_messages = []
            
            # è½¬æ¢ä¸­æ–‡é€‰é¡¹ä¸ºå†…éƒ¨ä½¿ç”¨çš„è‹±æ–‡å€¼
            position_en = self.get_position_preset(position)
            font_rgb = self.get_color_rgb(font_color)
            background_rgb = self.get_color_rgb(background_color)
            text_alignment = self.get_text_alignment(text_alignment_cn)
            
            # å¤„ç†æ–‡æœ¬æ¢è¡Œ
            wrapped_text = self.wrap_text(text_content, max_chars_per_line)
            text_stats = self.get_text_stats(wrapped_text)
            
            # æ­¥éª¤1: æ˜¾ç¤ºé…ç½®ä¿¡æ¯
            progress.log_progress("åˆå§‹åŒ–é…ç½®", f"æ–‡æœ¬: '{text_content[:20]}{'...' if len(text_content) > 20 else ''}'", 10.0)
            log_messages.append(f"å¼€å§‹å¤„ç†æ–‡æœ¬è¦†ç›–: '{text_content}'")
            log_messages.append(f"æ¢è¡Œåæ–‡æœ¬: {text_stats['total_lines']}è¡Œ, æœ€é•¿{text_stats['max_line_length']}å­—ç¬¦")
            log_messages.append(f"ä½ç½®: {position}, å­—ä½“å¤§å°: {font_size}")
            log_messages.append(f"ä½ç½®è®¡ç®—: æŒ‰è§†é¢‘é«˜åº¦æ¯”ä¾‹è‡ªé€‚åº”")
            log_messages.append(f"å­—ä½“é¢œè‰²: {font_color} {font_rgb}")
            log_messages.append(f"èƒŒæ™¯é¢œè‰²: {background_color} {background_rgb}")
            log_messages.append(f"èƒŒæ™¯é€æ˜åº¦: {background_opacity}")
            
            # åˆ›å»ºæ ·å¼é…ç½®
            style = TextOverlayStyle()
            style.position_preset = position_en
            style.font_size = font_size
            style.font_color = font_rgb
            style.background_color = background_rgb
            style.background_opacity = background_opacity if background_color != "é€æ˜" else 0.0
            style.background_enabled = enable_background and background_color != "é€æ˜"
            style.font_bold = font_bold
            style.text_alignment = text_alignment
            style.enable_shadow = enable_shadow
            style.enable_border = enable_border
            style.margin_x = margin_x
            style.margin_y = margin_y
            
            # æ˜¾ç¤ºä½ç½®è®¡ç®—è¯¦æƒ…ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            x_expr, y_expr = style.get_position_expression(1920, 1080)  # ä½¿ç”¨æ ‡å‡†åˆ†è¾¨ç‡è®¡ç®—ç¤ºä¾‹
            log_messages.append(f"ä½ç½®è¡¨è¾¾å¼: x={x_expr}, y={y_expr}")
            
            # æ­¥éª¤2: éªŒè¯æ ·å¼é…ç½®
            progress.log_progress("éªŒè¯æ ·å¼é…ç½®", f"ä½ç½®: {position}, å¤§å°: {font_size}px", 20.0)
            is_valid, error_msg = self.service.validate_style(style)
            if not is_valid:
                error_message = f"âŒ æ ·å¼é…ç½®é”™è¯¯: {error_msg}"
                progress.log_error(error_message)
                log_messages.append(error_message)
                return images, "\n".join(log_messages)
            
            # æ­¥éª¤3: å‡†å¤‡ä¸´æ—¶æ–‡ä»¶
            progress.log_progress("å‡†å¤‡ä¸´æ—¶æ–‡ä»¶", "åˆ›å»ºè¾“å…¥è¾“å‡ºæ–‡ä»¶", 30.0)
            
            # ç”±äºComfyUIä¸­å›¾åƒå¤„ç†é€šå¸¸åœ¨å†…å­˜ä¸­è¿›è¡Œï¼Œ
            # è¿™é‡Œæˆ‘ä»¬éœ€è¦å°†å›¾åƒåºåˆ—è½¬æ¢ä¸ºä¸´æ—¶è§†é¢‘æ–‡ä»¶è¿›è¡Œå¤„ç†
            log_messages.append("æ­£åœ¨è½¬æ¢å›¾åƒåºåˆ—ä¸ºä¸´æ—¶è§†é¢‘...")
            
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix='.mp4', delete=False) as temp_input:
                temp_input_path = temp_input.name
            
            with tempfile.NamedTemporaryFile(suffix='.mp4', delete=False) as temp_output:
                temp_output_path = temp_output.name
            
            try:
                # æ­¥éª¤4: è½¬æ¢å›¾åƒåºåˆ—ä¸ºè§†é¢‘
                progress.log_progress("è½¬æ¢å›¾åƒåºåˆ—", f"ä¸´æ—¶æ–‡ä»¶: {os.path.basename(temp_input_path)}", 40.0)
                success = self._images_to_video(images, temp_input_path)
                if not success:
                    error_message = "âŒ å›¾åƒåºåˆ—è½¬æ¢ä¸ºè§†é¢‘å¤±è´¥"
                    progress.log_error(error_message)
                    log_messages.append(error_message)
                    return images, "\n".join(log_messages)
                
                progress.log_progress("å›¾åƒåºåˆ—è½¬æ¢å®Œæˆ", "å‡†å¤‡æ·»åŠ æ–‡æœ¬è¦†ç›–", 60.0)
                log_messages.append("âœ… å›¾åƒåºåˆ—è½¬æ¢å®Œæˆ")
                
                # æ­¥éª¤5: æ·»åŠ æ–‡æœ¬è¦†ç›–
                progress.log_progress("æ·»åŠ æ–‡æœ¬è¦†ç›–", f"ä½¿ç”¨FFmpegå¤„ç†", 70.0)
                log_messages.append("æ­£åœ¨æ·»åŠ æ–‡æœ¬è¦†ç›–...")
                success = self.service.add_text_overlay(
                    temp_input_path, wrapped_text, temp_output_path, style
                )
                
                if not success:
                    error_message = "âŒ æ–‡æœ¬è¦†ç›–æ·»åŠ å¤±è´¥"
                    progress.log_error(error_message)
                    log_messages.append(error_message)
                    return images, "\n".join(log_messages)
                
                progress.log_progress("æ–‡æœ¬è¦†ç›–å®Œæˆ", "å¼€å§‹è½¬æ¢å›å›¾åƒåºåˆ—", 85.0)
                log_messages.append("âœ… æ–‡æœ¬è¦†ç›–æ·»åŠ å®Œæˆ")
                
                # æ­¥éª¤6: å°†å¤„ç†åçš„è§†é¢‘è½¬æ¢å›å›¾åƒåºåˆ—
                progress.log_progress("è½¬æ¢å›å›¾åƒåºåˆ—", f"è¾“å‡ºæ–‡ä»¶: {os.path.basename(temp_output_path)}", 90.0)
                log_messages.append("æ­£åœ¨è½¬æ¢å›å›¾åƒåºåˆ—...")
                processed_images = self._video_to_images(temp_output_path)
                
                if processed_images is None:
                    error_message = "âŒ è§†é¢‘è½¬æ¢ä¸ºå›¾åƒåºåˆ—å¤±è´¥"
                    progress.log_error(error_message)
                    log_messages.append(error_message)
                    return images, "\n".join(log_messages)
                
                # æ­¥éª¤7: å®Œæˆå¤„ç†
                progress.log_success("æ–‡æœ¬è¦†ç›–å¤„ç†å®Œæˆï¼")
                log_messages.append("âœ… å¤„ç†å®Œæˆï¼")
                print("="*60)
                return processed_images, "\n".join(log_messages)
                
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    os.unlink(temp_input_path)
                    os.unlink(temp_output_path)
                except:
                    pass
                
        except Exception as e:
            error_msg = f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
            log_messages.append(error_msg)
            return images, "\n".join(log_messages)
    
    def _images_to_video(self, images, output_path: str) -> bool:
        """
        å°†å›¾åƒåºåˆ—è½¬æ¢ä¸ºè§†é¢‘æ–‡ä»¶
        
        Args:
            images: å›¾åƒåºåˆ—
            output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
            
        Returns:
            è½¬æ¢æ˜¯å¦æˆåŠŸ
        """
        try:
            import torch
            import numpy as np
            from PIL import Image
            import subprocess
            import tempfile
            import os
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•ä¿å­˜å›¾åƒ
            temp_dir = tempfile.mkdtemp()
            
            try:
                # å°†å¼ é‡è½¬æ¢ä¸ºPILå›¾åƒå¹¶ä¿å­˜
                if isinstance(images, torch.Tensor):
                    # ç¡®ä¿å¼ é‡åœ¨CPUä¸Š
                    images = images.cpu()
                    
                    # è½¬æ¢å¼ é‡æ ¼å¼ [batch, height, width, channels] -> [batch, channels, height, width]
                    if images.dim() == 4 and images.shape[-1] in [1, 3, 4]:
                        images = images.permute(0, 3, 1, 2)
                    
                    for i, img_tensor in enumerate(images):
                        # è½¬æ¢ä¸ºnumpyæ•°ç»„
                        img_np = img_tensor.permute(1, 2, 0).numpy()
                        
                        # ç¡®ä¿å€¼åœ¨0-255èŒƒå›´å†…
                        if img_np.max() <= 1.0:
                            img_np = (img_np * 255).astype(np.uint8)
                        else:
                            img_np = np.clip(img_np, 0, 255).astype(np.uint8)
                        
                        # è½¬æ¢ä¸ºPILå›¾åƒ
                        if img_np.shape[2] == 1:
                            pil_img = Image.fromarray(img_np.squeeze(), mode='L')
                        elif img_np.shape[2] == 3:
                            pil_img = Image.fromarray(img_np, mode='RGB')
                        else:
                            pil_img = Image.fromarray(img_np[:,:,:3], mode='RGB')
                        
                        # ä¿å­˜å›¾åƒ
                        pil_img.save(os.path.join(temp_dir, f"frame_{i:06d}.png"))
                
                # ä½¿ç”¨FFmpegå°†å›¾åƒåºåˆ—è½¬æ¢ä¸ºè§†é¢‘
                cmd = [
                    'ffmpeg', '-y',
                    '-framerate', '30',  # é»˜è®¤å¸§ç‡
                    '-i', os.path.join(temp_dir, 'frame_%06d.png'),
                    '-c:v', 'libx264',
                    '-pix_fmt', 'yuv420p',
                    output_path
                ]
                
                result = subprocess.run(cmd, capture_output=True, text=True)
                
                if result.returncode == 0:
                    return True
                else:
                    logging.error(f"FFmpegè½¬æ¢å¤±è´¥: {result.stderr}")
                    return False
                    
            finally:
                # æ¸…ç†ä¸´æ—¶ç›®å½•
                import shutil
                shutil.rmtree(temp_dir, ignore_errors=True)
                
        except Exception as e:
            logging.error(f"å›¾åƒåºåˆ—è½¬æ¢ä¸ºè§†é¢‘æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False
    
    def _video_to_images(self, video_path: str):
        """
        å°†è§†é¢‘æ–‡ä»¶è½¬æ¢ä¸ºå›¾åƒåºåˆ—
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            å›¾åƒå¼ é‡æˆ–None
        """
        try:
            import torch
            import numpy as np
            from PIL import Image
            import subprocess
            import tempfile
            import os
            import re
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•
            temp_dir = tempfile.mkdtemp()
            
            try:
                # ä½¿ç”¨FFmpegæå–å¸§
                cmd = [
                    'ffmpeg', '-y',
                    '-i', video_path,
                    '-f', 'image2',
                    os.path.join(temp_dir, 'frame_%06d.png')
                ]
                
                result = subprocess.run(cmd, capture_output=True, text=True)
                
                if result.returncode != 0:
                    logging.error(f"FFmpegæå–å¸§å¤±è´¥: {result.stderr}")
                    return None
                
                # è¯»å–æå–çš„å›¾åƒ
                frame_files = sorted([f for f in os.listdir(temp_dir) if f.endswith('.png')])
                
                if not frame_files:
                    logging.error("æœªæ‰¾åˆ°æå–çš„å¸§")
                    return None
                
                images = []
                for frame_file in frame_files:
                    frame_path = os.path.join(temp_dir, frame_file)
                    pil_img = Image.open(frame_path).convert('RGB')
                    
                    # è½¬æ¢ä¸ºnumpyæ•°ç»„
                    img_np = np.array(pil_img).astype(np.float32) / 255.0
                    
                    # è½¬æ¢ä¸ºå¼ é‡
                    img_tensor = torch.from_numpy(img_np)
                    images.append(img_tensor)
                
                # å †å ä¸ºæ‰¹æ¬¡å¼ é‡
                if images:
                    return torch.stack(images)
                else:
                    return None
                    
            finally:
                # æ¸…ç†ä¸´æ—¶ç›®å½•
                import shutil
                shutil.rmtree(temp_dir, ignore_errors=True)
                
        except Exception as e:
            logging.error(f"è§†é¢‘è½¬æ¢ä¸ºå›¾åƒåºåˆ—æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return None


# ComfyUIèŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "TextOverlayVideoNode": TextOverlayVideoNode
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "TextOverlayVideoNode": "ğŸ“ Text Overlay Video"
}

# å¦‚æœç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶ï¼Œè¿›è¡Œæµ‹è¯•
if __name__ == "__main__":
    # ç®€å•æµ‹è¯•
    node = TextOverlayVideoNode()
    print("âœ… TextOverlayVideoNode èŠ‚ç‚¹åˆ›å»ºæˆåŠŸ")
    print("ğŸ“‹ èŠ‚ç‚¹è¾“å…¥ç±»å‹:", node.INPUT_TYPES())
