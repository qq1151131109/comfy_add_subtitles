"""
ComfyUIè‡ªå®šä¹‰èŠ‚ç‚¹ï¼šæ–‡æœ¬è¦†ç›–è§†é¢‘èŠ‚ç‚¹
ä¸ºè§†é¢‘æ·»åŠ è‡ªå®šä¹‰æ–‡æœ¬è¦†ç›–åŠŸèƒ½
"""

import os
import sys
import logging
import tempfile
from typing import Dict, Any, Tuple

# æ·»åŠ çˆ¶ç›®å½•åˆ°Pythonè·¯å¾„ä»¥æ”¯æŒå¯¼å…¥
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

try:
    from ..services.text_overlay_service import TextOverlayService, TextOverlayStyle, TextAlignment
except ImportError:
    from services.text_overlay_service import TextOverlayService, TextOverlayStyle, TextAlignment


class TextOverlayVideoNode:
    """ComfyUIæ–‡æœ¬è¦†ç›–è§†é¢‘èŠ‚ç‚¹"""
    
    def __init__(self):
        self.service = TextOverlayService()
        
    @classmethod
    def INPUT_TYPES(cls):
        """å®šä¹‰èŠ‚ç‚¹è¾“å…¥ç±»å‹"""
        return {
            "required": {
                "images": ("IMAGE", {
                    "tooltip": "è¾“å…¥å›¾åƒåºåˆ—ï¼ˆæ¥è‡ªè§†é¢‘æˆ–å›¾åƒå¤„ç†èŠ‚ç‚¹ï¼‰"
                }),
                "text_content": ("STRING", {
                    "default": "åœ¨è¿™é‡Œè¾“å…¥æ–‡æœ¬å†…å®¹",
                    "multiline": True,
                    "placeholder": "è¦æ˜¾ç¤ºåœ¨è§†é¢‘ä¸Šçš„æ–‡æœ¬"
                }),
                "position": ([
                    "bottom_center",    # åº•éƒ¨å±…ä¸­
                    "bottom_left",      # åº•éƒ¨å·¦å¯¹é½
                    "bottom_right",     # åº•éƒ¨å³å¯¹é½
                    "top_center",       # é¡¶éƒ¨å±…ä¸­
                    "top_left",         # é¡¶éƒ¨å·¦å¯¹é½
                    "top_right",        # é¡¶éƒ¨å³å¯¹é½
                    "center",           # å±å¹•ä¸­å¤®
                    "center_left",      # ä¸­å¤®å·¦å¯¹é½
                    "center_right"      # ä¸­å¤®å³å¯¹é½
                ], {
                    "default": "bottom_center",
                    "tooltip": "æ–‡æœ¬åœ¨è§†é¢‘ä¸­çš„ä½ç½®"
                }),
                "font_size": ("INT", {
                    "default": 24,
                    "min": 12,
                    "max": 72,
                    "step": 1,
                    "tooltip": "å­—ä½“å¤§å°ï¼ˆåƒç´ ï¼‰"
                }),
                "font_color_r": ("INT", {
                    "default": 0,
                    "min": 0,
                    "max": 255,
                    "step": 1,
                    "tooltip": "å­—ä½“é¢œè‰²çº¢è‰²åˆ†é‡"
                }),
                "font_color_g": ("INT", {
                    "default": 0,
                    "min": 0,
                    "max": 255,
                    "step": 1,
                    "tooltip": "å­—ä½“é¢œè‰²ç»¿è‰²åˆ†é‡"
                }),
                "font_color_b": ("INT", {
                    "default": 0,
                    "min": 0,
                    "max": 255,
                    "step": 1,
                    "tooltip": "å­—ä½“é¢œè‰²è“è‰²åˆ†é‡"
                }),
                "background_color_r": ("INT", {
                    "default": 255,
                    "min": 0,
                    "max": 255,
                    "step": 1,
                    "tooltip": "èƒŒæ™¯é¢œè‰²çº¢è‰²åˆ†é‡"
                }),
                "background_color_g": ("INT", {
                    "default": 255,
                    "min": 0,
                    "max": 255,
                    "step": 1,
                    "tooltip": "èƒŒæ™¯é¢œè‰²ç»¿è‰²åˆ†é‡"
                }),
                "background_color_b": ("INT", {
                    "default": 255,
                    "min": 0,
                    "max": 255,
                    "step": 1,
                    "tooltip": "èƒŒæ™¯é¢œè‰²è“è‰²åˆ†é‡"
                }),
                "background_opacity": ("FLOAT", {
                    "default": 0.8,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.1,
                    "tooltip": "èƒŒæ™¯é€æ˜åº¦ï¼ˆ0=å®Œå…¨é€æ˜ï¼Œ1=å®Œå…¨ä¸é€æ˜ï¼‰"
                })
            },
            "optional": {
                "enable_background": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "æ˜¯å¦å¯ç”¨æ–‡å­—èƒŒæ™¯"
                }),
                "font_bold": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "æ˜¯å¦ä½¿ç”¨ç²—ä½“å­—"
                }),
                "text_alignment": ([
                    "center",
                    "left", 
                    "right"
                ], {
                    "default": "center",
                    "tooltip": "æ–‡æœ¬å¯¹é½æ–¹å¼"
                }),
                "enable_shadow": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "æ˜¯å¦å¯ç”¨æ–‡å­—é˜´å½±"
                }),
                "enable_border": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "æ˜¯å¦å¯ç”¨æ–‡å­—è¾¹æ¡†"
                }),
                "margin_x": ("INT", {
                    "default": 50,
                    "min": 0,
                    "max": 200,
                    "step": 5,
                    "tooltip": "æ°´å¹³è¾¹è·ï¼ˆåƒç´ ï¼‰"
                }),
                "margin_y": ("INT", {
                    "default": 50,
                    "min": 0,
                    "max": 200,
                    "step": 5,
                    "tooltip": "å‚ç›´è¾¹è·ï¼ˆåƒç´ ï¼‰"
                })
            }
        }
    
    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("images", "processing_log")
    FUNCTION = "process_text_overlay"
    CATEGORY = "Video/Text"
    OUTPUT_NODE = False
    
    def process_text_overlay(self, images, text_content: str, position: str, 
                           font_size: int, font_color_r: int, font_color_g: int, font_color_b: int,
                           background_color_r: int, background_color_g: int, background_color_b: int,
                           background_opacity: float, **kwargs) -> Tuple[Any, str]:
        """
        å¤„ç†æ–‡æœ¬è¦†ç›–
        
        Args:
            images: è¾“å…¥å›¾åƒåºåˆ—
            text_content: æ–‡æœ¬å†…å®¹
            position: ä½ç½®
            font_size: å­—ä½“å¤§å°
            font_color_r, font_color_g, font_color_b: å­—ä½“é¢œè‰²RGB
            background_color_r, background_color_g, background_color_b: èƒŒæ™¯é¢œè‰²RGB
            background_opacity: èƒŒæ™¯é€æ˜åº¦
            **kwargs: å…¶ä»–å¯é€‰å‚æ•°
            
        Returns:
            (å¤„ç†åçš„å›¾åƒåºåˆ—, å¤„ç†æ—¥å¿—)
        """
        try:
            # è·å–å¯é€‰å‚æ•°
            enable_background = kwargs.get("enable_background", True)
            font_bold = kwargs.get("font_bold", False)
            text_alignment = kwargs.get("text_alignment", "center")
            enable_shadow = kwargs.get("enable_shadow", False)
            enable_border = kwargs.get("enable_border", False)
            margin_x = kwargs.get("margin_x", 50)
            margin_y = kwargs.get("margin_y", 50)
            
            log_messages = []
            log_messages.append(f"å¼€å§‹å¤„ç†æ–‡æœ¬è¦†ç›–: '{text_content}'")
            log_messages.append(f"ä½ç½®: {position}, å­—ä½“å¤§å°: {font_size}")
            log_messages.append(f"å­—ä½“é¢œè‰²: RGB({font_color_r}, {font_color_g}, {font_color_b})")
            log_messages.append(f"èƒŒæ™¯é¢œè‰²: RGB({background_color_r}, {background_color_g}, {background_color_b})")
            
            # åˆ›å»ºæ ·å¼é…ç½®
            style = TextOverlayStyle()
            style.position_preset = position
            style.font_size = font_size
            style.font_color = (font_color_r, font_color_g, font_color_b)
            style.background_color = (background_color_r, background_color_g, background_color_b)
            style.background_opacity = background_opacity
            style.background_enabled = enable_background
            style.font_bold = font_bold
            style.text_alignment = text_alignment
            style.enable_shadow = enable_shadow
            style.enable_border = enable_border
            style.margin_x = margin_x
            style.margin_y = margin_y
            
            # éªŒè¯æ ·å¼é…ç½®
            is_valid, error_msg = self.service.validate_style(style)
            if not is_valid:
                error_message = f"âŒ æ ·å¼é…ç½®é”™è¯¯: {error_msg}"
                log_messages.append(error_message)
                return images, "\n".join(log_messages)
            
            # ç”±äºComfyUIä¸­å›¾åƒå¤„ç†é€šå¸¸åœ¨å†…å­˜ä¸­è¿›è¡Œï¼Œ
            # è¿™é‡Œæˆ‘ä»¬éœ€è¦å°†å›¾åƒåºåˆ—è½¬æ¢ä¸ºä¸´æ—¶è§†é¢‘æ–‡ä»¶è¿›è¡Œå¤„ç†
            log_messages.append("æ­£åœ¨è½¬æ¢å›¾åƒåºåˆ—ä¸ºä¸´æ—¶è§†é¢‘...")
            
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix='.mp4', delete=False) as temp_input:
                temp_input_path = temp_input.name
            
            with tempfile.NamedTemporaryFile(suffix='.mp4', delete=False) as temp_output:
                temp_output_path = temp_output.name
            
            try:
                # å°†å›¾åƒåºåˆ—ä¿å­˜ä¸ºä¸´æ—¶è§†é¢‘
                success = self._images_to_video(images, temp_input_path)
                if not success:
                    error_message = "âŒ å›¾åƒåºåˆ—è½¬æ¢ä¸ºè§†é¢‘å¤±è´¥"
                    log_messages.append(error_message)
                    return images, "\n".join(log_messages)
                
                log_messages.append("âœ… å›¾åƒåºåˆ—è½¬æ¢å®Œæˆ")
                
                # æ·»åŠ æ–‡æœ¬è¦†ç›–
                log_messages.append("æ­£åœ¨æ·»åŠ æ–‡æœ¬è¦†ç›–...")
                success = self.service.add_text_overlay(
                    temp_input_path, text_content, temp_output_path, style
                )
                
                if not success:
                    error_message = "âŒ æ–‡æœ¬è¦†ç›–æ·»åŠ å¤±è´¥"
                    log_messages.append(error_message)
                    return images, "\n".join(log_messages)
                
                log_messages.append("âœ… æ–‡æœ¬è¦†ç›–æ·»åŠ å®Œæˆ")
                
                # å°†å¤„ç†åçš„è§†é¢‘è½¬æ¢å›å›¾åƒåºåˆ—
                log_messages.append("æ­£åœ¨è½¬æ¢å›å›¾åƒåºåˆ—...")
                processed_images = self._video_to_images(temp_output_path)
                
                if processed_images is None:
                    error_message = "âŒ è§†é¢‘è½¬æ¢ä¸ºå›¾åƒåºåˆ—å¤±è´¥"
                    log_messages.append(error_message)
                    return images, "\n".join(log_messages)
                
                log_messages.append("âœ… å¤„ç†å®Œæˆï¼")
                return processed_images, "\n".join(log_messages)
                
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    os.unlink(temp_input_path)
                    os.unlink(temp_output_path)
                except:
                    pass
                
        except Exception as e:
            error_msg = f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
            log_messages.append(error_msg)
            return images, "\n".join(log_messages)
    
    def _images_to_video(self, images, output_path: str) -> bool:
        """
        å°†å›¾åƒåºåˆ—è½¬æ¢ä¸ºè§†é¢‘æ–‡ä»¶
        
        Args:
            images: å›¾åƒåºåˆ—
            output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
            
        Returns:
            è½¬æ¢æ˜¯å¦æˆåŠŸ
        """
        try:
            import torch
            import numpy as np
            from PIL import Image
            import subprocess
            import tempfile
            import os
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•ä¿å­˜å›¾åƒ
            temp_dir = tempfile.mkdtemp()
            
            try:
                # å°†å¼ é‡è½¬æ¢ä¸ºPILå›¾åƒå¹¶ä¿å­˜
                if isinstance(images, torch.Tensor):
                    # ç¡®ä¿å¼ é‡åœ¨CPUä¸Š
                    images = images.cpu()
                    
                    # è½¬æ¢å¼ é‡æ ¼å¼ [batch, height, width, channels] -> [batch, channels, height, width]
                    if images.dim() == 4 and images.shape[-1] in [1, 3, 4]:
                        images = images.permute(0, 3, 1, 2)
                    
                    for i, img_tensor in enumerate(images):
                        # è½¬æ¢ä¸ºnumpyæ•°ç»„
                        img_np = img_tensor.permute(1, 2, 0).numpy()
                        
                        # ç¡®ä¿å€¼åœ¨0-255èŒƒå›´å†…
                        if img_np.max() <= 1.0:
                            img_np = (img_np * 255).astype(np.uint8)
                        else:
                            img_np = np.clip(img_np, 0, 255).astype(np.uint8)
                        
                        # è½¬æ¢ä¸ºPILå›¾åƒ
                        if img_np.shape[2] == 1:
                            pil_img = Image.fromarray(img_np.squeeze(), mode='L')
                        elif img_np.shape[2] == 3:
                            pil_img = Image.fromarray(img_np, mode='RGB')
                        else:
                            pil_img = Image.fromarray(img_np[:,:,:3], mode='RGB')
                        
                        # ä¿å­˜å›¾åƒ
                        pil_img.save(os.path.join(temp_dir, f"frame_{i:06d}.png"))
                
                # ä½¿ç”¨FFmpegå°†å›¾åƒåºåˆ—è½¬æ¢ä¸ºè§†é¢‘
                cmd = [
                    'ffmpeg', '-y',
                    '-framerate', '30',  # é»˜è®¤å¸§ç‡
                    '-i', os.path.join(temp_dir, 'frame_%06d.png'),
                    '-c:v', 'libx264',
                    '-pix_fmt', 'yuv420p',
                    output_path
                ]
                
                result = subprocess.run(cmd, capture_output=True, text=True)
                
                if result.returncode == 0:
                    return True
                else:
                    logging.error(f"FFmpegè½¬æ¢å¤±è´¥: {result.stderr}")
                    return False
                    
            finally:
                # æ¸…ç†ä¸´æ—¶ç›®å½•
                import shutil
                shutil.rmtree(temp_dir, ignore_errors=True)
                
        except Exception as e:
            logging.error(f"å›¾åƒåºåˆ—è½¬æ¢ä¸ºè§†é¢‘æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False
    
    def _video_to_images(self, video_path: str):
        """
        å°†è§†é¢‘æ–‡ä»¶è½¬æ¢ä¸ºå›¾åƒåºåˆ—
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            å›¾åƒå¼ é‡æˆ–None
        """
        try:
            import torch
            import numpy as np
            from PIL import Image
            import subprocess
            import tempfile
            import os
            import re
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•
            temp_dir = tempfile.mkdtemp()
            
            try:
                # ä½¿ç”¨FFmpegæå–å¸§
                cmd = [
                    'ffmpeg', '-y',
                    '-i', video_path,
                    '-f', 'image2',
                    os.path.join(temp_dir, 'frame_%06d.png')
                ]
                
                result = subprocess.run(cmd, capture_output=True, text=True)
                
                if result.returncode != 0:
                    logging.error(f"FFmpegæå–å¸§å¤±è´¥: {result.stderr}")
                    return None
                
                # è¯»å–æå–çš„å›¾åƒ
                frame_files = sorted([f for f in os.listdir(temp_dir) if f.endswith('.png')])
                
                if not frame_files:
                    logging.error("æœªæ‰¾åˆ°æå–çš„å¸§")
                    return None
                
                images = []
                for frame_file in frame_files:
                    frame_path = os.path.join(temp_dir, frame_file)
                    pil_img = Image.open(frame_path).convert('RGB')
                    
                    # è½¬æ¢ä¸ºnumpyæ•°ç»„
                    img_np = np.array(pil_img).astype(np.float32) / 255.0
                    
                    # è½¬æ¢ä¸ºå¼ é‡
                    img_tensor = torch.from_numpy(img_np)
                    images.append(img_tensor)
                
                # å †å ä¸ºæ‰¹æ¬¡å¼ é‡
                if images:
                    return torch.stack(images)
                else:
                    return None
                    
            finally:
                # æ¸…ç†ä¸´æ—¶ç›®å½•
                import shutil
                shutil.rmtree(temp_dir, ignore_errors=True)
                
        except Exception as e:
            logging.error(f"è§†é¢‘è½¬æ¢ä¸ºå›¾åƒåºåˆ—æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return None


# ComfyUIèŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "TextOverlayVideoNode": TextOverlayVideoNode
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "TextOverlayVideoNode": "ğŸ“ Text Overlay Video"
}

# å¦‚æœç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶ï¼Œè¿›è¡Œæµ‹è¯•
if __name__ == "__main__":
    # ç®€å•æµ‹è¯•
    node = TextOverlayVideoNode()
    print("âœ… TextOverlayVideoNode èŠ‚ç‚¹åˆ›å»ºæˆåŠŸ")
    print("ğŸ“‹ èŠ‚ç‚¹è¾“å…¥ç±»å‹:", node.INPUT_TYPES())
